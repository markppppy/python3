{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- encoding: utf-8 -*-\n",
    "# @Directory: D:\\Document\\local_rps\\python3\\scripts\n",
    "# @File     : psm_demo.ipynb\n",
    "# @Time     : 2022/01/28 11:25:45\n",
    "# @Author   : songpeiyao \n",
    "# @Version  : 1.0\n",
    "# @Contact  : ppppy161@qq.com\n",
    "# @Desc     : None\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import patsy\n",
    "import sys\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "import statsmodels.api as sm \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 读取文件，数据处理方便被模型计算的形式\n",
    "# 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() # 获取当前的路径\n",
    "file = path + \"/data.txt\"  # 写具体的引用文件名，该文件数据包括所有的X变量和Y变量（0，1）\n",
    "df = pd.read_csv(file,sep='\\t')  # 结合具体文件类型，若为txt文件则用read_csv, excel 则用read_excel\n",
    "\n",
    "X_field = ['X1','X2','X3','X4','X5','X6'] \n",
    "Y_field = ['Y']\n",
    "field = X_field + Y_field\n",
    "\n",
    "data = df[field]\n",
    "data = data.dropna()   # 去除任何包含无效数据的行\n",
    "treated = data[data['Y']==1]\n",
    "control = data[data['Y']==0]\n",
    "treated[field].describe().round(2)   # PSM前对照组和实验组的差异\n",
    "control[field].describe().round(2)\n",
    "\n",
    "data.groupby(Y_field).size()  # 原数据样本量大小\n",
    "treated_sample = treated.sample(10000,axis=0)[field].reset_index(drop=True)  # 实验组\n",
    "control_sample = control.sample(100000,axis=0)[field].reset_index(drop=True)  # 对照组，数据量必须大于实验组数据量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p = control_sample.append(treated_sample).reset_index(drop=True)  # 两个筛选的数据集为回归基础数据\n",
    "y_f, x_f = patsy.dmatrices('{} ~ {}'.format(Y_field[0], '+'.join(X_field)), data=data_p, return_type='dataframe')\n",
    "formula = '{} ~ {}'.format(Y_field[0], '+'.join(X_field))\n",
    "print('Formula:\\n'+formula)\n",
    "print('n majority:', len(control_sample))\n",
    "print('n minority:', len(treated_sample))  \n",
    "\n",
    "# 确定回归方程\n",
    "i=0   \n",
    "nmodels=50  # 可指定归回模型个数  应该叫循环次数\n",
    "errors=0\n",
    "model_accuracy = []\n",
    "models = []\n",
    "while i < nmodels and errors < 5:\n",
    "     sys.stdout.write('\\r{}: {}\\{}'.format(\"Fitting Models on Balanced Samples\", i, nmodels)) # 第几个模型  \n",
    "     control_sample.sample(len(treated_sample)).append(treated_sample).dropna()  # 模型选择相同数量的对照组和控制组样本\n",
    "     y_samp, X_samp = patsy.dmatrices(formula, data=df, return_type='dataframe')  # 选出模型的自变量和因变量\n",
    "     glm = GLM(y_samp, X_samp, family=sm.families.Binomial())  # 逻辑回归模型 \n",
    "     try:\n",
    "         res = glm.fit()\n",
    "         preds = [1.0 if i >= .5 else 0.0 for i in res.predict(X_samp)]     \n",
    "         preds=pd.DataFrame(preds)\n",
    "         preds.columns=y_samp.columns\n",
    "         b=y_samp.reset_index(drop=True)\n",
    "         a=preds.reset_index(drop=True)\n",
    "         ab_score=((a.sort_index().sort_index(axis=1) == b.sort_index().sort_index(axis=1)).sum() * 1.0 / len(y_samp)).values[0] # 模型预测准确性得分\n",
    "         model_accuracy.append(ab_score) \n",
    "         models.append(res) \n",
    "         i += 1 \n",
    "     except Exception as e:\n",
    "         errors += 1\n",
    "         print('Error: {}'.format(e))\n",
    "\n",
    "print(\"\\nAverage Accuracy:\", \"{}%\". format(round(np.mean(model_accuracy) * 100, 2)))  # 所有模型的平均准确性\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.001\n",
    "method='min'\n",
    "nmatches=1\n",
    "test_scores = data_p[data_p[Y_field[0]]==True][['scores']]\n",
    "ctrl_scores = data_p[data_p[Y_field[0]]==False][['scores']]\n",
    "result, match_ids = [], []\n",
    "for i in range(len(test_scores)):\n",
    "    match_id = i\n",
    "    score = test_scores.iloc[i]\n",
    "    matches = abs(ctrl_scores - score).sort_values('scores').head(nmatches)\n",
    "    chosen = np.random.choice(matches.index,  nmatches, replace=False)     \n",
    "    result.extend([test_scores.index[i]] + list(chosen))\n",
    "    match_ids.extend([i] * (len(chosen)+1))\n",
    "    ctrl_scores=ctrl_scores.drop(chosen,axis=0)\n",
    "matched_data =data_p.loc[result]\n",
    "matched_data['match_id'] = match_ids\n",
    "matched_data['record_id'] = matched_data.index\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
