主要工作内容：
目前负责未来轻轻BI-python的应用和算法服务的开发集成工作

代码相关：
根据情况选择先聚合再关联，还是先关联再聚合
前端传过来参数需要用到udf函数解析时，先解析，再与外表关联

cboard是报表展现平台
edw是开发平台
extradata是取数平台
bptconfig是埋点配置平台

数据分析组
ETL数仓组
数据模型组
数据产品开发组

陈彦  销售  (对已有线索，发展成单)
林进祯  师资
童亦凡  市场 、品牌、技术客服、客服、SEO

windows terminal生成目录结构命令: 1) cd /d xxx 到指定目录 2) tree /f 循环生成目录结构；tree 生成目录结构；

关闭mysql任务：
SHOW PROCESSLIST
KILL 11695212

Hive 
collect_set后是数组类型，转字符串只需要concat_ws(',',collect_set(col))就可以

判断当前日期是周几 pmod(datediff('2020-02-06', '1920-01-01') - 3, 7) --> 4

linux hive 结果集写入到文本文件： hive -e 'select ...' > /../featurn_1.txt
hive -f filename.sql > featurn_1.txt
hive3加载环境: 
unset HIVE_HOME HIVE_CONF_DIR HADOOP_HOME HADOOP_CONF_DIR
export JAVA_HOME=/usr/local/jdk8
(hive3先加载环境，然后用这个命令) /usr/hdp/current/hive-client/bin/hive -f get_data.sql > match_feature_data.txt  

分割生成的文本文件： split -l 400000 -d -a 1 leads_for_tmk_0708.txt leads_for_tmk_
-l 400000 是指每40W行分一次 
-d 是指文件结尾是数字 -a 1 是指结尾数字的位数 -a 2 的话就是 leads_for_tmk_02

切割后的文件是没有后缀名的，下载到本机后，改后缀名为.txt，然后在excel中用"自文本"加载，再保存就可以

hive -f filename.sql 2> filename.log 错误信息

hive -f filename.sql >> filename.log 2>&1  全部信息

文件处理
sed -e '/teacher_id/d' match_feature_data.txt |sed 's/+[-]*//g' |sed 's/^[\|]*//g' |sed 's/[\|]*$//g' |sed 's/ //g' |sed 's/[\|]/\t/g' |tr -d ''|sed '/^\s*$/d' > match_feature_data_imitate.txt
# sed -i 是在源文件中处理, -e 是处理后输出

解决预发布环境修改指标删除不掉之前用户建立的目录问题：
1、在10.1.150.237环境执行：kinit -k -t /usr/local/hadoop/etc/hadoop/hadoop.keytab hive-pr/$HOSTNAME@KERBEROS.BIGDATA.IDC.CEDU.CN
2、连上hive环境删除对应分区
3、删除hdfs上的对应：目录hadoop fs -rm -r /data/hive/warehouse/pr_apiprofile_mobdb.db/tr_profile/kpi_code=trCenterHasCourseStudentCnt

从linux拉取数据文件到本地：sz 'filename.txt'
上传：rz

海风测试数据
全职老师ID：149825

运维，权限问题找 "运维-DB"服务号

EDW的ADHOC界面输入sql界面可以检查异常字符。

准确率\精确率\召回率
假设：
TP: 将正类预测为正类数 40
FN: 将正类预测为负类数 20
FP: 将负类预测为正类数 10
TN: 将负类预测为负类数 30

准确率 = 预测对的 / 所有 = (TP + TN) / (TP + FN + FP + TN)
精确率 = TP / (TP + FP) 预测为正的样本，有多少是预测对的 分母：所有被预测为正类的样本  查准
召回率 = TP / (TP + FN) 样本中的正类，有多少被预测对了   分母：所有的正类  查全

loss：训练集的损失值。
val_loss：测试集的损失值。
常规训练规律：
loss下降，val_loss下降：训练网络正常，最好情况。
loss下降，val_loss稳定：网络过拟合化，可以使用正则化和Max pooling。
loss稳定，val_loss下降：数据集有严重问题，建议重新选择。
loss稳定，val_loss稳定：学习过程遇到瓶颈，需要减小学习率或批量数目，可以减少学习率。
loss上升，val_loss上升：网络结构设计问题，训练超参数设置不当，数据集经过清洗等问题，最差情况。
以上的下降、稳定和上升指的是整体训练趋势。

lightGBM的优点：
    基于 Histogram 的决策树算法  !!!
    带深度限制的 Leaf-wise 的叶子生长策略  !!!
    直方图做差加速  !!!
    直接支持类别特征(Categorical Feature)
    Cache 命中率优化
    基于直方图的稀疏特征优化
    多线程优化
参考：https://blog.csdn.net/weixin_39807102/article/details/81912566?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param#141-histogram-%E7%AE%97%E6%B3%95

信息增益，熵，条件熵
熵：表示随机变量的不确定性;
条件熵：在条件下，随机变量的不确定性;
信息增益: 熵 减去 条件熵, 即 不确定性的减少程度;
举例：
明天下雨是随机变量X, X的熵就是明天下雨的不确定性;
明天阴天是随机变量Y, 明天阴天的前提下, 下雨的不确定性, 即Y条件下X的熵 就是条件熵; 
X的熵 减去 Y条件下X的熵 就是信息增益, 含义是：明天下雨的信息熵是2, 条件熵是0.01(因为如果明天是阴天，下雨的概率很大)
  , 获得明天阴天这个信息后, 下雨的不确定性减少了1.99, 不确定性减少了很多，所以信息增益大, 即明天阴天对明天下雨这一推断很重要。

熵和概率的关系？
参考: https://www.cnblogs.com/kyrieng/p/8694705.html


样本平衡
样本平衡：1、取全部负例，把正例复制N倍，达到正例：负例 = 1:1
          2、在模型中，调整权重、因子，使得正负例达到平衡；具体百度：如何平衡正负例样本

linux 执行命令加\时，后面不要带空格！


pytho异常捕捉：


mongo条件操作符：
$gt -------- greater than  >
$gte --------- gt equal  >=
$lt -------- less than  <
$lte --------- lt equal  <=
$ne ----------- not equal  !=
$eq  --------  equal  =

新EDW，迁移过程中使用不便的地方：
TDM指标创建后，描述不能修改；
修改记录是覆盖而不是追加；

数据分析的变与不变：
数据分析的本质是从数据中找规律，变得是找规律的方法；

新基建？促进数据行业
大数据的发展，对数分的影响在哪？
数据的存储
数据的查询

-- 机器学习 算法 模型 
1、样本不平衡，导致分类效果差的理论依据：
前置条件：模型训练过程中，是根据loss的值来优化的
解释：样本不平衡如：正例：负例 = 9：1，训练过程中正样本的loss会占主导，如果评价标准是准确率，那么将所有样本预测为正例，就有90%的准确率。
拓展：如果是使用概率判断的分类问题，默认阈值是50%，可以根据正负样本比例调整阈值(阈值移动)

2、怎么解决正负例不平衡的问题：
情况1、训练样本比例和真实数据样本比例相同
方法1、调整损失函数，对类别占比小的样本更大的权重系数 ？ 调整比例和 
方法2、交叉熵函数 ？



-- 轻轻基本数据统计 老师的数据呢？
9.25: 从当前历史数据看，上过测评课或首课的家长到转化率为50%；注册到上测评课的转化只有不到10%，是注册用户中的有效用户(如：有孩子，适龄等)占比较少？还是这个环节不够重视？

下一步：1、统计注册用户中的有效用户数
       2、统计公司续费转化情况

参考数据：1、艾媒《2019-2020中国在线教育行业发展研究报告》 ZM注册用户3600W ?

-- CRM用户数：8930250
select count(1)
from   dws_mobdb.dws_pty_customer_basic_info;

-- 注册用户数：6274158
select count(1)
from   dws_mobdb.dws_pty_customer_basic_info
where  student_id is not null;

-- 上过测评课或试听课的学生数(包含已转化粒子)：444633
select count(distinct student_id) cnt
from   dws_mobdb.dws_agrt_course
where  if_first_course = 1 or if_reckon_before = 1

-- 注册转化的粒子数：203450
select  count(distinct student_id) -- 转化的家长
from    dws_mobdb.dws_agrt_order
where   if_standard_order = 1 and student_id is not null

-- 在读学员数：每月截止月末 还有剩余课次的学生数，不看当月是否有结课
         线上    线下 
2020.06  41260   32219
2020.07  42537   30620

select 
from   

-- 月流水：成单交易额
2020.07  116,299,592 

select 
from   


-- 退费金额
2020.07  10,678,552

select
from

-- 财务确认收入（平台分成）
2020.07  42,054,841

-- 新签用户数
月份      总     线上    线下
2020.05  5921   4492   1429
2020.06  5581   4558   1023
2020.07  4942   4139   803

-- 在职老师 13251
select  count(distinct teacher_id) cnt
from    odm_mobdb.odm_teacher_attribute_tag
where   tag_type = 55 and tag_value = 1
  and   tag_status = 0

-- 在职助教 6497
select count(distinct assistant_id)
from   dwd_mobdb.dwd_pty_assistant
where resignation_time is null and status = 1

-- 项目监控日志
以bicoursesche为例，在kibana上选择logtrail，settings 选择：
1、rsyslog-ingress*，输入 bicoursesche 查找，可以看到每次调用bicoursesche接口的状态和时间
2、rsyslog-app*, 输入 bicoursesche 查找，可以看到每次调用bisvc bicoursesche 接口的传入值，点击guid, 可以看到调用接口后，返回的老师数量，具体返回的老师id和评分，在mongo中查看
  
-- 配工程时给运维的信息：
GIT地址：https://gitlab.changingedu.com/dataplatform/BI_DOCKER_TRIALCOURSE_ARRANGEMENT_SERVICE
上下文：bitrailcourse
启动命令：CMD ["python","./biDockerTrialCourseArrangementService/courseScheRun.py"]
检测接口：/bitrailcourse/api/pb/ok.html
监听服务端口：8080
(之后配置文件要在Apollo上配)配置文件内容和配置文件的path路径：/home/qingqing/data/conf.ini   /home/qingqing/data/confRun.ini



推荐：排序

搜索：nlp解析，召回，排序

风控：根据信用数据对用户排序

广告：用户有可能感兴趣的内容排序

共同点：召回，排序

区别：业务指标

+ 用户画像


新环境建表语句：
drop table if exists tmp_mobdb.tmp_crm_agrt_transform_pipeline;
create table tmp_mobdb.tmp_crm_agrt_transform_pipeline
(student_id bigint
 ,predict_true double
)
row format delimited fields terminated by '\001'
stored as textfile;

tmp_mobdb.tmp_spy_predict_section 分值区间表，里面只有一个字符串字段，值类似为：[0, 0.1)



